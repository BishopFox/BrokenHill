{
	"entries":
	[
		{
			"model_name": "APT-1B-Base",
			"model_release": "APT",
			"model_family": "Azurro APT",
			"model_repository": "https://huggingface.co/Azurro/APT-1B-Base",
			"direct_developer_or_publisher": "Azurro",
			"model_path": "Azurro/APT-1B-Base",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama2",
			"size": 4241896185,
			"data_type": "float32",
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "APT2-1B-Base",
			"model_release": "APT2",
			"model_family": "Azurro APT",
			"model_repository": "https://huggingface.co/Azurro/APT2-1B-Base",
			"direct_developer_or_publisher": "Azurro",
			"model_path": "Azurro/APT2-1B-Base",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama2",
			"size": 3816970200,
			"data_type": "float32",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "APT3-1B-Instruct-v1",
			"model_release": "APT3",
			"model_family": "Azurro APT",
			"model_repository": "https://huggingface.co/Azurro/APT3-1B-Instruct-v1",
			"direct_developer_or_publisher": "Azurro",
			"model_path": "Azurro/APT3-1B-Instruct-v1",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama2",
			"size": 4167035336,
			"data_type": "float32",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "APT3-1B-Base",
			"model_release": "APT3",
			"model_family": "Azurro APT",
			"model_repository": "https://huggingface.co/Azurro/APT3-1B-Base",
			"direct_developer_or_publisher": "Azurro",
			"model_path": "Azurro/APT3-1B-Base",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama2",
			"size": 4167035336,
			"data_type": "float32",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "alpaca-13b",
			"model_release": "Alpaca",
			"model_family": "Alpaca",
			"model_repository": "https://huggingface.co/chavinlo/alpaca-13b",
			"direct_developer_or_publisher": "chavinlo",
			"model_path": "chavinlo/alpaca-13b",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "alpaca",
			"size": 52063646628,
			"data_type": "float32",
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ],
			"comment": "Takes just under 6.5 hours to smoke-test this model on the test system in CPU mode."
		},
		{
			"model_name": "huge-roadrunner-pythia-1b-deduped-oasst",
			"model_release": "huge-roadrunner-pythia-1b-deduped-oasst",
			"model_family": "huge-roadrunner-pythia-1b-deduped-oasst",
			"model_repository": "https://huggingface.co/csimokat/huge-roadrunner-pythia-1b-deduped-oasst",
			"direct_developer_or_publisher": "Chris Simokat",
			"model_path": "csimokat/huge-roadrunner-pythia-1b-deduped-oasst",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "oasst_pythia",
			"size": 4114319709,
			"data_type": "float32",
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "gpt-j-6b",
			"model_release": "GPT-J",
			"model_family": "GPT-J",
			"model_repository": "https://huggingface.co/EleutherAI/gpt-j-6b",
			"direct_developer_or_publisher": "Eleuther AI",
			"model_path": "EleutherAI/gpt-j-6b",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 24207819307,
			"safe_tensors": false,
			"custom_options": [],
			"comment": "This model seems to hang during the second iteration - doesn't finish even at ten hours."
		},
		{
			"model_name": "gpt-neo-1.3B",
			"model_release": "GPT-Neo",
			"model_family": "GPT-Neo",
			"model_repository": "https://huggingface.co/EleutherAI/gpt-neo-1.3B",
			"direct_developer_or_publisher": "Eleuther AI",
			"model_path": "EleutherAI/gpt-neo-1.3B",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 5312673800,
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "gpt-neox-20b",
			"model_release": "GPT-NeoX",
			"model_family": "GPT-NeoX",
			"model_repository": "https://huggingface.co/EleutherAI/gpt-neox-20b",
			"direct_developer_or_publisher": "Eleuther AI",
			"model_path": "EleutherAI/gpt-neox-20b",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "gptneox",
			"size": 41293763742,
			"data_type": "float16",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests", "--missing-pad-token-replacement", "unk" ],
			"comment": "Takes about 9.5 hours to smoke-test this model on the test system in CPU mode. Need to validate the missing pad token replacement."
		},
		{
			"model_name": "pythia-1.4b",
			"model_release": "Pythia",
			"model_family": "Pythia",
			"model_repository": "https://huggingface.co/EleutherAI/pythia-1.4b",
			"direct_developer_or_publisher": "Eleuther AI",
			"model_path": "EleutherAI/pythia-1.4b",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 2930002184,
			"data_type": "float16",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "bart-large-cnn",
			"model_release": "BART",
			"model_family": "BART",
			"model_repository": "https://huggingface.co/Facebook/bart-large-cnn",
			"direct_developer_or_publisher": "Meta",
			"model_path": "Facebook/bart-large-cnn",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 1625222120,
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests", "--max-new-tokens-final", "128" ]
		},
		{
			"model_name": "blenderbot-3B",
			"model_release": "BlenderBot",
			"model_family": "BlenderBot",
			"model_repository": "https://huggingface.co/Facebook/blenderbot-3B",
			"direct_developer_or_publisher": "Meta",
			"model_path": "Facebook/blenderbot-3B",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 5474698716,
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests", "--max-new-tokens", "32", "--max-new-tokens-final", "32" ]
		},
		{
			"model_name": "opt-2.7b",
			"model_release": "OPT",
			"model_family": "OPT",
			"model_repository": "https://huggingface.co/Facebook/opt-2.7b",
			"direct_developer_or_publisher": "Meta",
			"model_path": "Facebook/opt-2.7b",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 5303359381,
			"data_type": "float16",
			"safe_tensors": false,
			"custom_options": [ "--max-new-tokens-final", "128" ]
		},
		{
			"model_name": "roberta-base",
			"model_release": "RoBERTa",
			"model_family": "RoBERTa",
			"model_repository": "https://huggingface.co/FacebookAI/roberta-base",
			"direct_developer_or_publisher": "Meta",
			"model_path": "FacebookAI/roberta-base",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 498818054,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Llama-68M-Chat-v1",
			"model_release": "Felladrin-Llama-68M-Chat-v1",
			"model_family": "Felladrin-Llama-68M",
			"model_repository": "https://huggingface.co/Felladrin/Llama-68M-Chat-v1",
			"direct_developer_or_publisher": "Victor Nogueira",
			"model_path": "Felladrin/Llama-68M-Chat-v1",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "felladrin-llama-chat",
			"size": 272123144,
			"data_type": "float32",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "Guanaco-3B-Uncensored-v2",
			"model_family": "Fredithefish-Guanaco-Uncensored",
			"model_path": "Fredithefish/Guanaco-3B-Uncensored-v2",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "guanaco",
			"size": 5551783000,
			"data_type": "float16",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "bigbird-pegasus-large-pubmed",
			"model_family": "",
			"model_path": "Google/bigbird-pegasus-large-pubmed",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 2308148159,
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests", "--max-new-tokens", "32", "--max-new-tokens-final", "32" ]
		},
		{
			"model_name": "flan-t5-xl",
			"model_family": "",
			"model_path": "Google/flan-t5-xl",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 11399097584,
			"safe_tensors": true,
			"custom_options": [],
			"comment": "This is a T5 model, which is not currently supported in Broken Hill."
		},
		{
			"model_name": "gemma-2b-it",
			"model_family": "",
			"model_path": "Google/gemma-2b-it",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "gemma+",
			"size": 5012363872,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "gemma-1.1-2b-it",
			"model_family": "",
			"model_path": "Google/gemma-1.1-2b-it",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "gemma+",
			"size": 5012363872,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "gemma-2-2b-it",
			"model_family": "",
			"model_path": "Google/gemma-2-2b-it",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "gemma+",
			"size": 5228717488,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "pegasus-wikihow",
			"model_family": "",
			"model_path": "Google/pegasus-wikihow",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 2275329241,
			"safe_tensors": false,
			"custom_options": [ "--max-new-tokens-final", "128" ]
		},
		{
			"model_name": "bert-base-cased",
			"model_family": "",
			"model_path": "google-bert/bert-base-cased",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 435755784,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "SmolLM-135M-Instruct",
			"model_family": "",
			"model_path": "HuggingFaceTB/SmolLM-135M-Instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "smollm",
			"size": 269060552,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "SmolLM-1.7B-Instruct",
			"model_family": "",
			"model_path": "HuggingFaceTB/SmolLM-1.7B-Instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "smollm",
			"size": 3422777952,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "neural-chat-7b-v3-3",
			"model_family": "",
			"model_path": "Intel/neural-chat-7b-v3-3",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "mistral",
			"size": 14483563691,
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ],
			"comment": "Takes about 2.75 hours to smoke-test this model on the test system in CPU mode."
		},
		{
			"model_name": "GPT-NeoX-20B-Erebus",
			"model_release": "GPT-NeoX-20B-Erebus",
			"model_family": "GPT-NeoX-20B-Erebus",
			"model_repository": "https://huggingface.co/KoboldAI/GPT-NeoX-20B-Erebus",
			"direct_developer_or_publisher": "KoboldAI",
			"model_path": "KoboldAI/GPT-NeoX-20B-Erebus",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "gptneox",
			"size": 41293881230,
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests", "--missing-pad-token-replacement", "unk" ],
			"comment": "Takes about 9.75 hours to smoke-test this model on the test system in CPU mode. Need to validate the missing pad token replacement value."
		},
		{
			"model_name": "OPT-6.7B-Erebus",
			"model_release": "OPT-6.7B-Erebus",
			"model_family": "OPT-6.7B-Erebus",
			"model_repository": "https://huggingface.co/KoboldAI/OPT-6.7B-Erebus",
			"direct_developer_or_publisher": "KoboldAI",
			"model_path": "KoboldAI/OPT-6.7B-Erebus",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 13317059541,
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "fastchat-t5-3b-v1.0",
			"model_family": "",
			"model_path": "lmsys/fastchat-t5-3b-v1.0",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 6706187737,
			"safe_tensors": false,
			"custom_options": [],
			"comment": "This is a T5 model, which is not currently supported in Broken Hill."
		},
		{
			"model_name": "vicuna-7b-v1.1",
			"model_family": "",
			"model_path": "lmsys/vicuna-7b-v1.1",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "vicuna_v1.1",
			"size": 13476950097,
			"safe_tensors": false,
			"custom_options": []
		},
		{
			"model_name": "vicuna-7b-v1.3",
			"model_family": "",
			"model_path": "lmsys/vicuna-7b-v1.3",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "vicuna_v1.1",
			"size": 13476950097,
			"safe_tensors": false,
			"custom_options": []
		},
		{
			"model_name": "vicuna-7b-v1.5",
			"model_family": "",
			"model_path": "lmsys/vicuna-7b-v1.5",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "vicuna_v1.1",
			"size": 13476950097,
			"safe_tensors": false,
			"custom_options": []
		},
		{
			"model_name": "llama-7b",
			"model_family": "",
			"model_path": "huggyllama/llama-7b",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama2",
			"size": 13476876661,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Llama-2-7b-chat-hf",
			"model_family": "",
			"model_path": "Meta/Llama-2-7b-chat-hf",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama2",
			"size": 13476872576,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Meta-Llama-3-8B-Instruct",
			"model_family": "",
			"model_path": "meta-llama/Meta-Llama-3-8B-Instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama-3",
			"size": 16060556376,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Meta-Llama-3.1-8B-Instruct",
			"model_family": "",
			"model_path": "meta-llama/Meta-Llama-3.1-8B-Instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama-3",
			"size": 16060556376,
			"safe_tensors": true,
			"custom_options": [ "--system-prompt-from-file", "BrokenHill/data/llama3_system_prompt.txt" ]
		},
		{
			"model_name": "Meta-Llama-Guard-2-8B",
			"model_family": "",
			"model_path": "meta-llama/Meta-Llama-Guard-2-8B",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama-3",
			"size": 16060556376,
			"safe_tensors": true,
			"custom_options": [ ]
		},
		{
			"model_name": "Llama-Guard-3-8B",
			"model_family": "",
			"model_path": "meta-llama/Llama-Guard-3-8B",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama-3",
			"size": 16060556376,
			"safe_tensors": true,
			"custom_options": [ ]
		},
		{
			"model_name": "Orca-2-7b",
			"model_family": "",
			"model_path": "Microsoft/Orca-2-7b",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "orca-2",
			"size": 26953860317,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "phi-1",
			"model_family": "",
			"model_path": "Microsoft/phi-1",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 2836578696,
			"data_type": "float32",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "phi-1_5",
			"model_family": "",
			"model_path": "Microsoft/phi-1_5",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 2836578696,
			"data_type": "float16",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "phi-2",
			"model_family": "",
			"model_path": "Microsoft/phi-2",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "phi2",
			"size": 5559417400,
			"data_type": "float16",
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Phi-3-mini-128k-instruct",
			"model_family": "",
			"model_path": "Microsoft/Phi-3-mini-128k-instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "phi3",
			"size": 7642181880,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Phi-3-small-128k-instruct",
			"model_family": "",
			"model_path": "Microsoft/Phi-3-small-128k-instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "phi3",
			"size": 14784589056,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Phi-3-medium-128k-instruct",
			"model_family": "",
			"model_path": "Microsoft/Phi-3-medium-128k-instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "phi3",
			"size": 27920504728,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Phi-3.5-mini-instruct",
			"model_family": "",
			"model_path": "Microsoft/Phi-3.5-mini-instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "phi3",
			"size": 7642181880,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": [ ]
		},
		{
			"model_name": "Mistral-7B-Instruct-v0.2",
			"model_family": "",
			"model_path": "MistralAI/Mistral-7B-Instruct-v0.2",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "mistral",
			"size": 14483498016,
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "Mistral-7B-Instruct-v0.3",
			"model_family": "",
			"model_path": "MistralAI/Mistral-7B-Instruct-v0.3",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "mistral",
			"size": 14496078512,
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "Mistral-Nemo-Instruct-2407",
			"model_family": "",
			"model_path": "MistralAI/Mistral-Nemo-Instruct-2407",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "mistral",
			"size": 24495604224,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Mixtral-8x7B-Instruct-v0.1",
			"model_family": "",
			"model_path": "MistralAI/Mixtral-8x7B-Instruct-v0.1",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "mistral",
			"size": 93405713504,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Daredevil-7B",
			"model_family": "",
			"model_path": "mlabonne/Daredevil-7B",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "daredevil",
			"size": 14483498040,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "NeuralDaredevil-7B",
			"model_family": "",
			"model_path": "mlabonne/NeuralDaredevil-7B",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "daredevil",
			"size": 14483497728,
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "mpt-1b-redpajama-200b-dolly",
			"model_family": "",
			"model_path": "mosaicml/mpt-1b-redpajama-200b-dolly",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "mpt",
			"size": 5245893681,
			"data_type": "float32",
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests", "--trust-remote-code" ]
		},
		{
			"model_name": "mpt-7b-chat",
			"model_family": "",
			"model_path": "mosaicml/mpt-7b-chat",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "mpt",
			"size": 13298639462,
			"safe_tensors": false,
			"custom_options": []
		},
		{
			"model_name": "gpt2",
			"model_family": "",
			"model_path": "OpenAI/gpt2",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 548105171,
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests", "--max-new-tokens-final", "128" ]
		},
		{
			"model_name": "gpt2-medium",
			"model_family": "",
			"model_path": "openai-community/gpt2-medium",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 1519984962,
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "galactica-6.7b-finetuned",
			"model_family": "",
			"model_path": "OpenAssistant/galactica-6.7b-finetuned",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 27448883928,
			"safe_tensors": false,
			"custom_options": []
		},
		{
			"model_name": "oasst-rm-2.1-pythia-1.4b-epoch-2.5",
			"model_family": "",
			"model_path": "OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "oasst_pythia",
			"size": 5347161969,
			"safe_tensors": false,
			"custom_options": [],
			"comment": "This is a reward model, not a general-purpose text generator/chat model - it will fail in Broken Hill."
		},
		{
			"model_name": "oasst-sft-4-pythia-12b-epoch-3.5",
			"model_family": "",
			"model_path": "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "oasst_pythia",
			"size": 23835137461,
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "openchat-3.6-8b-20240522",
			"model_family": "",
			"model_path": "openchat/openchat-3.6-8b-20240522",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama-3",
			"size": 16060556384,
			"safe_tensors": true,
			"custom_options": [],
			"comment": "openchat_3.5 seems like it would be the correct template, but is not"
		},
		{
			"model_name": "Qwen-7B-Chat",
			"model_family": "",
			"model_path": "Qwen/Qwen-7B-Chat",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "qwen",
			"size": 15442677288,
			"safe_tensors": true,
			"custom_options": [ "--trust-remote-code" ]
		},
		{
			"model_name": "Qwen-1.8B-Chat",
			"model_family": "Qwen",
			"model_path": "Qwen/Qwen-1_8B-Chat",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "qwen",
			"size": 3673678272,
			"safe_tensors": true,
			"custom_options": [ "--trust-remote-code" ]
		},
		{
			"model_name": "Qwen1.5-0.5B-Chat",
			"model_family": "",
			"model_path": "Qwen/Qwen1.5-0.5B-Chat",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "qwen",
			"size": 1239173352,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Qwen1.5-1.8B-Chat",
			"model_family": "",
			"model_path": "Qwen/Qwen1.5-1.8B-Chat",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "qwen",
			"size": 3673690696,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Qwen2-0.5B-Instruct",
			"model_family": "",
			"model_path": "Qwen/Qwen2-0.5B-Instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "qwen2",
			"size": 988097824,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "Qwen2-1.5B-Instruct",
			"model_family": "",
			"model_path": "Qwen/Qwen2-1.5B-Instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "qwen2",
			"size": 3087467144,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "llama-3-youko-8b-instruct",
			"model_family": "",
			"model_path": "rinna/llama-3-youko-8b-instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama-3",
			"size": 16060556616,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "nekomata-7b-instruction",
			"model_family": "",
			"model_path": "rinna/nekomata-7b-instruction",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "alpaca",
			"size": 15442677504,
			"safe_tensors": true,
			"custom_options": [ "--trust-remote-code" ]
		},
		{
			"model_name": "youri-7b-chat",
			"model_family": "",
			"model_path": "rinna/youri-7b-chat",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 13476865232,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "snowflake-arctic-embed-s",
			"model_family": "",
			"model_path": "Snowflake/snowflake-arctic-embed-s",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 132870584,
			"data_type": "float32",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "stablelm-tuned-alpha-3b",
			"model_family": "",
			"model_path": "StabilityAI/stablelm-tuned-alpha-3b",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "stablelm",
			"size": 14817807231,
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "stablelm-2-1_6b-chat",
			"model_family": "",
			"model_path": "StabilityAI/stablelm-2-1_6b-chat",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "stablelm2",
			"size": 6578099872,
			"data_type": "float32",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "mamba-1.4b-hf",
			"model_family": "",
			"model_path": "state-spaces/mamba-1.4b-hf",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "zero_shot",
			"size": 5488766864,
			"data_type": "float32",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests", "--suppress-attention-mask" ]
		},
		{
			"model_name": "stable-vicuna-13B-HF",
			"model_family": "",
			"model_path": "TheBloke/stable-vicuna-13B-HF",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "stable-vicuna",
			"size": 26031897559,
			"safe_tensors": false,
			"custom_options": []
		},
		{
			"model_name": "guanaco-7B-HF",
			"model_family": "",
			"model_path": "TheBloke/guanaco-7B-HF",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "guanaco",
			"size": 13476950097,
			"safe_tensors": false,
			"custom_options": []
		},
		{
			"model_name": "chatglm-6b",
			"model_family": "",
			"model_path": "THUDM/chatglm-6b",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "chatglm",
			"size": 13416906785,
			"safe_tensors": false,
			"custom_options": [ "--trust-remote-code" ]
		},
		{
			"model_name": "chatglm2-6b",
			"model_family": "",
			"model_path": "THUDM/chatglm2-6b",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "chatglm2",
			"size": 12487241401,
			"safe_tensors": false,
			"custom_options": [ "--trust-remote-code" ]
		},
		{
			"model_name": "chatglm3-6b",
			"model_family": "",
			"model_path": "THUDM/chatglm3-6b",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "chatglm3",
			"size": 12487194904,
			"safe_tensors": true,
			"custom_options": [ "--trust-remote-code" ]
		},
		{
			"model_name": "glm-4-9b-chat",
			"model_family": "",
			"model_path": "THUDM/glm-4-9b-chat",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "chatglm3",
			"size": 18799941256,
			"safe_tensors": true,
			"custom_options": [ "--trust-remote-code" ]
		},
		{
			"model_name": "falcon-7b-instruct",
			"model_family": "",
			"model_path": "tiiuae/falcon-7b-instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "falcon",
			"size": 14434449852,
			"safe_tensors": false,
			"custom_options": []
		},
		{
			"model_name": "falcon-mamba-7b-instruct",
			"model_family": "",
			"model_path": "tiiuae/falcon-mamba-7b-instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "falcon",
			"size": 14545401832,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "guanaco-7b",
			"model_family": "",
			"model_path": "huggyllama/llama-7b",
			"tokenizer_path": "",
			"peft_path": "timdettmers/guanaco-7b",
			"template": "guanaco",
			"size": 13476876661,
			"safe_tensors": false,
			"custom_options": [],
			"comment": "Included as it's a test of the PEFT adapter functionality - size of the adapter is 639792909."
		},
		{
			"model_name": "TinyLlama-1.1B-Chat-v1.0",
			"model_family": "",
			"model_path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "TinyLlama",
			"size": 2200119864,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "GPT-NeoXT-Chat-Base-20B",
			"model_family": "",
			"model_path": "togethercomputer/GPT-NeoXT-Chat-Base-20B",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "gptneox",
			"size": 41293915901,
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "Pythia-Chat-Base-7B",
			"model_family": "",
			"model_path": "togethercomputer/Pythia-Chat-Base-7B",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "oasst_pythia",
			"size": 13848989318,
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "RedPajama-INCITE-7B-Chat",
			"model_family": "",
			"model_path": "togethercomputer/RedPajama-INCITE-7B-Chat",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "redpajama-incite",
			"size": 13848992454,
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "RedPajama-INCITE-Chat-3B-v1",
			"model_family": "",
			"model_path": "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "redpajama-incite",
			"size": 5686106713,
			"data_type": "float16",
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "Llama-3-Swallow-8B-Instruct-v0.1",
			"model_family": "",
			"model_path": "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama-3",
			"size": 16060556376,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Swallow-7b-instruct-hf",
			"model_family": "",
			"model_path": "tokyotech-llm/Swallow-7b-instruct-hf",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama2",
			"size": 13659972648,
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "Swallow-MS-7b-instruct-v0.1",
			"model_family": "",
			"model_path": "tokyotech-llm/Swallow-MS-7b-instruct-v0.1",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "llama2",
			"size": 14660445224,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "tiny-random-GPTNeoXForCausalLM-safetensors",
			"model_family": "",
			"model_path": "trl-internal-testing/tiny-random-GPTNeoXForCausalLM-safetensors",
			"tokenizer_path": "EleutherAI/gpt-neox-20b",
			"peft_path": "",
			"template": "gptneox",
			"size": 404996,
			"data_type": "float32",
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "SOLAR-10.7B-Instruct-v1.0",
			"model_family": "",
			"model_path": "upstage/SOLAR-10.7B-Instruct-v1.0",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "solar+",
			"size": 21463098376,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "TinySolar-248m-4k-code-instruct",
			"model_family": "",
			"model_path": "upstage/TinySolar-248m-4k-code-instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "solar+",
			"size": 496040208,
			"data_type": "bfloat16",
			"safe_tensors": true,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		},
		{
			"model_name": "Vikhr-7B-instruct_0.4",
			"model_family": "",
			"model_path": "Vikhrmodels/Vikhr-7B-instruct_0.4",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "vikhr",
			"size": 15255168080,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "Vikhr-Gemma-2B-instruct",
			"model_family": "",
			"model_path": "Vikhrmodels/Vikhr-Gemma-2B-instruct",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "gemma+",
			"size": 10457400944,
			"safe_tensors": true,
			"custom_options": []
		},
		{
			"model_name": "VikhrT5-240m",
			"model_family": "",
			"model_path": "Vikhrmodels/VikhrT5-240m",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "vikhr",
			"size": 1150886642,
			"safe_tensors": false,
			"custom_options": [],
			"comment": "This is a T5 model, which is not currently supported in Broken Hill."
		},
		{
			"model_name": "oasst_pythia-70m-deduped_webgpt",
			"model_family": "",
			"model_path": "WKLI22/oasst_pythia-70m-deduped_webgpt",
			"tokenizer_path": "",
			"peft_path": "",
			"template": "oasst_pythia",
			"size": 306838155,
			"data_type": "float32",
			"safe_tensors": false,
			"custom_options": [ "--ignore-jailbreak-self-tests" ]
		}
	]
}